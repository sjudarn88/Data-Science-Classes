# -*- coding: utf-8 -*-
"""1.PDF and CDF Calculation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/sjudarn88/b92596d62f18837cc150056f3c40dec9/1-pdf-and-cdf-calculation.ipynb

**Class Code 1: PDF and CDF Calculation**
"""

### Class Code 1: PDF and CDF Calculation
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm, t
from statsmodels.stats.weightstats import ztest
np.random.seed(0)

mu = 170
sd = 7

# generate samples from our distribution
x = norm.rvs(loc=mu, scale=sd, size=100)
# maximum likelihood mean
print(x.mean())
# maximum likelihood variance
print(x.var())
# variance sanity check
print(((x-x.mean())**2).mean())
# maximum likelihood std
print(x.std())
# unbiased variance, N-1
print(x.var(ddof=1))
# unbiased variance sanity check, N-1
print(((x-x.mean())**2).sum()/(len(x)-1))
#unbiased std
print(x.std(ddof=1))

# q1: at what height are you in the 95th percentile?
print(norm.ppf(0.95,loc=mu,scale=sd))
# q2: you are 160 cm tall, what percentile are you in?
print(norm.cdf(160,loc=mu, scale=sd))
# q3: you are 180 cm tall, what is the probability that someone is taller than you?
print(1-norm.cdf(180,loc=mu,scale=sd))
print(norm.sf(180,loc=mu,scale=sd))

"""**Class Code 2: Confidence Intervals**"""

# N is the number of samples
N = 1000
mu = 5
sigma = 2
X = np.random.randn(N)*sigma + mu

# Z-confidence interval
mu_hat = np.mean(X)
sigma_hat = np.std(X, ddof=1)
z_left = norm.ppf(0.025)
z_right = norm.ppf(0.975)
lower = mu_hat + z_left * sigma_hat/np.sqrt(N)
upper = mu_hat + z_right * sigma_hat/np.sqrt(N)
print(mu_hat,lower,upper)

# t-confidence interval
mu_hat = np.mean(X)
sigma_hat = np.std(X,ddof=1)
t_left = t.ppf(0.025,df=N-1)
t_right = t.ppf(0.975,df=N-1)
lower = mu_hat + t_left * sigma_hat/np.sqrt(N)
upper = mu_hat + t_right * sigma_hat/np.sqrt(N)
print(mu_hat,lower,upper)

def experiment():
  X = np.random.randn(N)*sigma + mu
  mu_hat = np.mean(X)
  sigma_hat = np.std(X,ddof=1)
  t_left = t.ppf(0.025,df=N-1)
  t_right = t.ppf(0.975,df=N-1)
  lower = mu_hat + t_left * sigma_hat/np.sqrt(N)
  upper = mu_hat + t_right * sigma_hat/np.sqrt(N)
  return mu>lower and mu<upper

def multi_experiment(M):
  R= [experiment() for _ in range(M)]
  return np.mean(R)

multi_experiment(10000)

"""**Class Code 2: Z-Test, P-Value, One-Sided Test, Two-Sided Test, and Two-Sample Test**"""

N = 100
mu = 0.2
sigma = 1
x=np.random.randn(N)*sigma +mu
#print(x)

# two-sided test
ztest(x)

# two-sided test
mu_hat = x.mean()
sigma_hat = x.std(ddof=1)
z = (mu_hat-0)/(sigma_hat/np.sqrt(N))
p_right = 1-norm.cdf(np.abs(z))
p_left = norm.cdf(-np.abs(z))
p = p_right + p_left
z,p

# Alternate calculation
mu_hat = x.mean()
v_hat=x.var(ddof=1)/N
z = (mu_hat-0)/np.sqrt(v_hat)
p = 2 * norm.sf(z)
z,p
###Note: you can use nor.sf instead of 1 - norm.cdf

# one-sided test
mu_hat = x.mean()
sigma_hat = x.std(ddof=1)
z = (mu_hat-0)/(sigma_hat/np.sqrt(N))
p = 1-norm.cdf(z)
z,p

# null under a different reference value
mu0 = 0.2
ztest(x,value=mu0)

mu_hat = x.mean()
sigma_hat = x.std(ddof=1)
z = (mu_hat-mu0)/(sigma_hat/np.sqrt(N))
p_right = 1 - norm.cdf(np.abs(z))
p_left = norm.cdf(-np.abs(z))
p = p_right + p_left
z,p

# two-sample test
N0 = 100
mu0 = 0.2
sigma0 = 1
x0 = np.random.randn(N0)*sigma0 + mu0

N1 = 100
mu1 = 0.5
sigma1 = 1
x1 = np.random.randn(N1)*sigma1 + mu1

ztest(x0,x1)

# two-sample test implementation
mu_hat0 = x0.mean()
mu_hat1 = x1.mean()
dmu_hat = mu_hat1 - mu_hat0
s2_hat0 = x0.var(ddof=1)
s2_hat1 = x1.var(ddof=1)
s_hat = np.sqrt(s2_hat0/N0 +s2_hat1/N1)
z = (dmu_hat-0)/s_hat
p_right = 1-norm.cdf(np.abs(z))
p_left = norm.cdf(-np.abs(z))
p = p_right + p_left
z,p

# show that we will reject the null hypothesis 
# when the null hypothesis is true (false alarm) 5% of the time
num_tests = 10000
results = np.zeros(num_tests)
for i in range(num_tests):
    x1 = np.random.randn(100)
    x2 = np.random.randn(100)
    z,p = ztest(x1,x2)
    results[i] = (p<0.05)
print(results.mean())

### real data practice -- Titanic
!wget https://lazyprogrammer.me/course_files/titanic_train.csv

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('titanic_train.csv')
df.head()

df[df['Survived']==1].head()

# Compare Fare value difference between 2 groups : survived and not survived
# use z-test to see if there is a significant difference between fare value from the 2 groups.
x1 = df[df['Survived']==1]['Fare'].dropna().to_numpy()
x2 = df[df['Survived']==0]['Fare'].dropna().to_numpy()

sns.kdeplot(x1,label='Survived')
sns.kdeplot(x2,label='Did Not Survive')
plt.legend()

x1.mean(),x2.mean()

# P-value < 0.05 or regular threshold we ususally use, 
# this means the fare value is significantly different between 'Survived' and 'Did Not Survived' Group.
ztest(x1,x2)

"""### AB Test E"""